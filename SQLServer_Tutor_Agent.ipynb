{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP2PxmycHWuFNlQmlTmAEEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majidraza1228/LLM/blob/LLM_Tech_Class/SQLServer_Tutor_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImY9YSgsnmh3"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.27.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPEN_API_KEY')"
      ],
      "metadata": {
        "id": "x5ptl7q_n87u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def generate_sql(prompt):\n",
        "  response = openai.ChatCompletion.create( # Changed from openai.Completion.create to openai.ChatCompletion.create\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, # Added system message for chat models\n",
        "        {\"role\": \"user\", \"content\": f\"Generate a SQL query for the following: {prompt}\"},\n",
        "    ],\n",
        "    max_tokens=150,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    temperature=0.7,\n",
        "  )\n",
        "  return response.choices[0].message.content.strip() # Accessing the message content for chat models"
      ],
      "metadata": {
        "id": "MIsDG2VNoKXd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        " # user_prompt = input(\"Enter your SQL question (or 'quit' to exit): \")\n",
        "  # if user_prompt.lower() == \"quit\":\n",
        "  #   break\n",
        "  user_prompt=\"What is Primary key\"\n",
        "  sql_query = generate_sql(user_prompt)\n",
        "  print(\"Generated SQL query:\", sql_query)\n",
        "  # You can add logic here to execute the query and display results"
      ],
      "metadata": {
        "id": "B1kMopVnoVzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}